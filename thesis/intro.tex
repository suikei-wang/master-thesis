\chapter{Introduction}
\label{cha:intro}

\section{Motivation}
\label{sec:motivation}




\section{Thesis Outline}
\label{sec:outline}
Following the two central themes we mentioned above, this thesis consists of two parts -- PART I Deep Declarative Network: Multiple Constrained Declarative Nodes and PART II Deep Declarative Nodes: Non-regular Solution. 
\par PART I focus on the regular points of multiple constrained declarative nodes in the deep declarative network, with some basic examples of different constraints nodes. 
\begin{description}
    \item In Chapter ~\ref{cha:overviewpart1}, we first give an overview of the theory of optimization, with the discussion of the optimality. Next, we formally define the unconstrained, equality constrained and inequality constrained problems. We then discuss the related works on the solutions to these problems. Finally, the differentiable neural network, an application of numerical optimization in machine learning, is briefly discussed with various modern deep learning algorithms.  
    \item In Chapter ~\ref{cha:ddn}, which is based on works of \cite{SG:19}, we present the details of the deep declarative network. We begin with the overview structure and how it works through the specific declarative nodes. We then introduce the learning progress of the deep declarative network. We analyze the backpropagation through the declarative nodes in different constrained problems. Finally, we give multiple examples of the implementation of the deep declarative nodes in both equality constrained and inequality constrained optimization problems. Also, we point out the limitation of current deep declarative nodes and address some foreseeable ideas for future improvements in the optimization process. We also look to the practical application of the deep declarative network in computer vision tasks.
\end{description}

\par PART II is an extension of the deep declarative nodes in non-regular solution problems, which cannot be solved through the traditional numerical optimization methods. Detailedly, we focus on the approximate solution of the non-regular points with different approaches, which can solve the problem more efficiently. 
\begin{description}
    \item In Chapter~\ref{cha:overviewpart2}, we give an overview of the non-regular solution problems. We list the general non-regular solution cases: overdetermined system, rand deficiency, and non-convex feasible set. We also introduce various related works regarding problems with non-regular gradient results. 
    \item In Chapter~\ref{cha:result}, we demonstrate various possible solutions for each non-regular point case. Since for non-regular solution problems, there are no exact solutions, we can only approximate the closed result. We also compare and discuss the results of each method on minimizing the final loss. Finally, we point out some future works for solving non-regular point problems. 
\end{description}
We will finally present the conclusion in Chapter~\ref{cha:conc}. Proofs for the important theorems and definitions are given in the Appendix.

\section{Contribution}
\label{sec.contribution}