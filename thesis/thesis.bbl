\begin{thebibliography}{24}
\providecommand{\natexlab}[1]{#1}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{}
\expandafter\ifx\csname urlstyle\endcsname\relax
  \providecommand{\doi}[1]{doi:\discretionary{}{}{}#1}\else
  \providecommand{\doi}{doi:\discretionary{}{}{}\begingroup
  \urlstyle{rm}\Url}\fi

\bibitem[{Agrawal et~al.(2019)Agrawal, Amos, Barratt, Boyd, Diamond, and
  Kolter}]{AA:19}
\textsc{Agrawal, A.; Amos, B.; Barratt, S.; Boyd, S.; Diamond, S.; and Kolter,
  J.~Z.}, 2019.
\newblock Differentiable convex optimization layers.
\newblock In \emph{Advances in neural information processing systems},
  9562--9574.

\bibitem[{Amos and Kolter(2017)}]{AB:17}
\textsc{Amos, B. and Kolter, J.~Z.}, 2017.
\newblock Optnet: Differentiable optimization as a layer in neural networks.
\newblock \emph{arXiv preprint arXiv:1703.00443},  (2017).

\bibitem[{Amos and Yarats(2019)}]{AB:19}
\textsc{Amos, B. and Yarats, D.}, 2019.
\newblock The differentiable cross-entropy method.
\newblock \emph{arXiv preprint arXiv:1909.12830},  (2019).

\bibitem[{Bertsekas(2014)}]{BD:14}
\textsc{Bertsekas, D.~P.}, 2014.
\newblock \emph{Constrained optimization and Lagrange multiplier methods}.
\newblock Academic press.

\bibitem[{Boyd et~al.(2004)Boyd, Boyd, and Vandenberghe}]{BS:04}
\textsc{Boyd, S.; Boyd, S.~P.; and Vandenberghe, L.}, 2004.
\newblock \emph{Convex optimization}.
\newblock Cambridge university press.

\bibitem[{Campbell et~al.(2020)Campbell, Liu, and Gould}]{CD:20}
\textsc{Campbell, D.; Liu, L.; and Gould, S.}, 2020.
\newblock Solving the blind perspective-n-point problem end-to-end with robust
  differentiable geometric optimization.
\newblock \emph{arXiv preprint arXiv:2007.14628},  (2020).

\bibitem[{Chen et~al.(2020)Chen, Parra, Cao, Li, and Chin}]{CB:20}
\textsc{Chen, B.; Parra, A.; Cao, J.; Li, N.; and Chin, T.-J.}, 2020.
\newblock End-to-end learnable geometric vision by backpropagating pnp
  optimization.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 8100--8109.

\bibitem[{Chen and Duvenaud(2019)}]{CR:19}
\textsc{Chen, R.~T. and Duvenaud, D.~K.}, 2019.
\newblock Neural networks with cheap differential operators.
\newblock In \emph{Advances in Neural Information Processing Systems},
  9961--9971.

\bibitem[{Debye(1909)}]{DP:09}
\textsc{Debye, P.}, 1909.
\newblock N{\"a}herungsformeln f{\"u}r die zylinderfunktionen f{\"u}r gro{\ss}e
  werte des arguments und unbeschr{\"a}nkt ver{\"a}nderliche werte des index.
\newblock \emph{Mathematische Annalen}, 67, 4  (1909), 535--558.

\bibitem[{Dennis and Mor{\'e}(1977)}]{DJ:77}
\textsc{Dennis, J.~E., Jr and Mor{\'e}, J.~J.}, 1977.
\newblock Quasi-newton methods, motivation and theory.
\newblock \emph{SIAM review}, 19, 1  (1977), 46--89.

\bibitem[{Goodfellow et~al.(2016)Goodfellow, Bengio, Courville, and
  Bengio}]{GI:16}
\textsc{Goodfellow, I.; Bengio, Y.; Courville, A.; and Bengio, Y.}, 2016.
\newblock \emph{Deep learning}, vol.~1.
\newblock MIT press Cambridge.

\bibitem[{Gould et~al.(2016)Gould, Fernando, Cherian, Anderson, Cruz, and
  Guo}]{SG:16}
\textsc{Gould, S.; Fernando, B.; Cherian, A.; Anderson, P.; Cruz, R.~S.; and
  Guo, E.}, 2016.
\newblock On differentiating parameterized argmin and argmax problems with
  application to bi-level optimization.
\newblock \emph{arXiv preprint arXiv:1607.05447},  (2016).

\bibitem[{Gould et~al.(2019)Gould, Hartley, and Campbell}]{SG:19}
\textsc{Gould, S.; Hartley, R.; and Campbell, D.}, 2019.
\newblock Deep declarative networks: A new hope.
\newblock \emph{arXiv preprint arXiv:1909.04866},  (2019).

\bibitem[{Hestenes(1969)}]{HM:69}
\textsc{Hestenes, M.~R.}, 1969.
\newblock Multiplier and gradient methods.
\newblock \emph{Journal of optimization theory and applications}, 4, 5  (1969),
  303--320.

\bibitem[{Jiang(1999)}]{JH:99}
\textsc{Jiang, H.}, 1999.
\newblock Global convergence analysis of the generalized newton and
  gauss-newton methods of the fischer-burmeister equation for the
  complementarity problem.
\newblock \emph{Mathematics of Operations Research}, 24, 3  (1999), 529--543.

\bibitem[{Newton and Colson(1736)}]{NT:36}
\textsc{Newton, I. and Colson, J.}, 1736.
\newblock \emph{The Method of Fluxions and Infinite Series; with Its
  Application to the Geometry of Curve-lines... Translated from the Author's
  Latin Original Not Yet Made Publick. To which is Subjoin'd a Perpetual
  Comment Upon the Whole Work... by J. Colson}.

\bibitem[{Niemeyer et~al.(2020)Niemeyer, Mescheder, Oechsle, and
  Geiger}]{NM:20}
\textsc{Niemeyer, M.; Mescheder, L.; Oechsle, M.; and Geiger, A.}, 2020.
\newblock Differentiable volumetric rendering: Learning implicit 3d
  representations without 3d supervision.
\newblock In \emph{Proceedings of the IEEE/CVF Conference on Computer Vision
  and Pattern Recognition}, 3504--3515.

\bibitem[{Nocedal and Wright(2006)}]{JS:06}
\textsc{Nocedal, J. and Wright, S.}, 2006.
\newblock \emph{Numerical optimization}.
\newblock Springer Science \& Business Media.

\bibitem[{Oman(2017)}]{OG:17}
\textsc{Oman, G.}, 2017.
\newblock A short proof of the bolzano-weierstrass theorem.
\newblock \emph{The College Mathematics Journal},  (2017).

\bibitem[{Panier et~al.(1988)Panier, Tits, and Herskovits}]{PE:88}
\textsc{Panier, E.~R.; Tits, A.~L.; and Herskovits, J.~N.}, 1988.
\newblock A qp-free, globally convergent, locally superlinearly convergent
  algorithm for inequality constrained optimization.
\newblock \emph{SIAM Journal on Control and Optimization}, 26, 4  (1988),
  788--811.

\bibitem[{Powell(1969)}]{PM:69}
\textsc{Powell, M.~J.}, 1969.
\newblock A method for nonlinear constraints in minimization problems.
\newblock \emph{Optimization},  (1969), 283--298.

\bibitem[{Qi and Qi(2000)}]{QH:00}
\textsc{Qi, H.-D. and Qi, L.}, 2000.
\newblock A new qp-free, globally convergent, locally superlinearly convergent
  algorithm for inequality constrained optimization.
\newblock \emph{SIAM Journal on Optimization}, 11, 1  (2000), 113--132.

\bibitem[{Wang et~al.(2019)Wang, Donti, Wilder, and Kolter}]{WP:19}
\textsc{Wang, P.-W.; Donti, P.~L.; Wilder, B.; and Kolter, Z.}, 2019.
\newblock Satnet: Bridging deep learning and logical reasoning using a
  differentiable satisfiability solver.
\newblock \emph{arXiv preprint arXiv:1905.12149},  (2019).

\bibitem[{Yeniay(2005)}]{YO:05}
\textsc{Yeniay, {\"O}.}, 2005.
\newblock Penalty function methods for constrained optimization with genetic
  algorithms.
\newblock \emph{Mathematical and computational Applications}, 10, 1  (2005),
  45--56.

\end{thebibliography}
